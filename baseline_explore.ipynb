{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Problem Undestanding\n",
    "Here we will look at a Data Science challenge within the IMDB space. For our model fitting choose the f1-score metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries & data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import SCORERS\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import re\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition constants\n",
    "RANDOM_STATE = 11\n",
    "MAX_ITER=4000\n",
    "NUMBER_K_FOLD = 5\n",
    "TARGET_METRIC = 'f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Vectorizer_description</th>\n",
       "      <th>F1 train</th>\n",
       "      <th>F1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, Preprocessing, Vectorizer, Vectorizer_description, F1 train, F1 test]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Results of exploring for model we will provided in table model_search_result\n",
    "model_search_result = pd.DataFrame(columns=['Model',\n",
    "                                            'Preprocessing',\n",
    "                                            'Vectorizer',\n",
    "                                            'Vectorizer_description',\n",
    "                                            'F1 train',\n",
    "                                            'F1 test', ], )\n",
    "model_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import & display data\n",
    "data = pd.read_csv('data/IMDB_Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "Our training set has 50K movie reviews for natural language processing.  This is a dataser for binary sentiment classification. \n",
    "For more dataset information, please go through the following link,\n",
    "https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       50000\n",
       "sentiment    50000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  negative\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataset contains invalid non-unique values. In the next step research we should drop all data repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>Quite what the producers of this appalling ada...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>My favourite police series of all time turns t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391</th>\n",
       "      <td>Beautiful film, pure Cassavetes style. Gena Ro...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6352</th>\n",
       "      <td>If you liked the Grinch movie... go watch that...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6479</th>\n",
       "      <td>I want very much to believe that the above quo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review sentiment\n",
       "3537  Quite what the producers of this appalling ada...  negative\n",
       "3769  My favourite police series of all time turns t...  positive\n",
       "4391  Beautiful film, pure Cassavetes style. Gena Ro...  positive\n",
       "6352  If you liked the Grinch movie... go watch that...  negative\n",
       "6479  I want very much to believe that the above quo...  negative"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replace the categoric values from 'sentiment' to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = data['sentiment'].replace({'positive' : 1, 'negative' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Splitting data for train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['review']\n",
    "y = data['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set: 35000\n",
      "Share of positive samples in train set: 0.5\n",
      "Size of test set: 15000\n",
      "Share of positive samples in test set: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('Size of train set: ' + str(X_train.size) +\n",
    "     '\\nShare of positive samples in train set: ' + str(y_train[y_train==1].count()/y_train.size))\n",
    "print('Size of test set: ' + str(X_test.size) +\n",
    "     '\\nShare of positive samples in test set: ' + str(y_test[y_test==1].count()/y_test.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying CountVectorizer for convert a collection of text documents to a matrix of token counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform on it the training features\n",
    "count_vectorizer.fit(X_train)\n",
    "X_train_features = count_vectorizer.transform(X_train)\n",
    "\n",
    "#transform the test features to sparse matrix\n",
    "X_test_features = count_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resulting the vocabulary dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['strangely',\n",
       " 'enjoyable',\n",
       " 'effort',\n",
       " 'combining',\n",
       " 'an',\n",
       " 'appropriately',\n",
       " 'far',\n",
       " 'fetched',\n",
       " 'plot',\n",
       " 'involving',\n",
       " 'adam',\n",
       " 'and',\n",
       " 'burt',\n",
       " 'flashbacks',\n",
       " 'to',\n",
       " 'the',\n",
       " 'original',\n",
       " 'tv',\n",
       " 'series',\n",
       " 'most']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(count_vectorizer.vocabulary_.keys())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# definition common function\n",
    "\n",
    "# add data to result table\n",
    "def add_model_to_result_table(resultTable, model, preprocessing, vectorizer, vectorizer_description, f1_train, f1_test):\n",
    "    modelItem = [model,\n",
    "                 preprocessing, \n",
    "                 vectorizer,    \n",
    "                 vectorizer_description,\n",
    "                 f1_train, \n",
    "                 f1_test]\n",
    "    if any([str(modelItem) == str(list(row[1][:])) for row in resultTable.iterrows()]):\n",
    "        return(resultTable)\n",
    "    resultTable.loc[resultTable.shape[0] + 1] = modelItem\n",
    "    return(resultTable)\n",
    "    \n",
    "# plot F1-score\n",
    "def plot_f1_curve(result_table):\n",
    "    \n",
    "    plt.title(\"A F1 score curve\")\n",
    "    labeles = ['F1 train', 'F1 test']\n",
    "    for l in labeles:\n",
    "        plt.plot(result_table.index, result_table[l], label =l)\n",
    "    plt.xlabel(\"Index the model from the result  table\")\n",
    "    plt.ylabel(\"f1\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=4000, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=11, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': array([1.00000000e-02, 1.93069773e-02, 3.72759372e-02, 7.19685673e-02,\n",
       "       1.38949549e-01, 2.68269580e-01, 5.17947468e-01, 1.00000000e+00,\n",
       "       1.93069773e+00, 3.72759372e+00, 7.19685673e+00, 1.38949549e+01,\n",
       "       2.68269580e+01, 5.17947468e+01, 1.00000000e+02])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams_log_reg = {\n",
    "    'C': np.logspace(-2, 2, 15), \n",
    "}\n",
    "\n",
    "logreg_model_cross_valid=LogisticRegression(random_state=RANDOM_STATE, max_iter=MAX_ITER)\n",
    "logreg_cv = GridSearchCV(logreg_model_cross_valid, \n",
    "                         hyperparams_log_reg, scoring =TARGET_METRIC, \n",
    "                         cv=NUMBER_K_FOLD, \n",
    "                         return_train_score=True )\n",
    "\n",
    "logreg_cv.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The best value F1 score for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8914672009081602"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The best estimator for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.07196856730011521, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=4000, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=11, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of Cross validation with 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_param</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0372759</td>\n",
       "      <td>0.892898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0719686</td>\n",
       "      <td>0.890122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0372759</td>\n",
       "      <td>0.897342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0719686</td>\n",
       "      <td>0.891403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0719686</td>\n",
       "      <td>0.887065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     C_param  F1-score\n",
       "0  0.0372759  0.892898\n",
       "1  0.0719686  0.890122\n",
       "2  0.0372759  0.897342\n",
       "3  0.0719686  0.891403\n",
       "4  0.0719686  0.887065"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result_cv = pd.DataFrame(columns = ['C_param', 'F1-score'], index = range(0,5))\n",
    "for splitN in range(5):\n",
    "    result_cv['F1-score'][splitN] = logreg_cv.cv_results_['split'+str(splitN)+'_test_score'].max()\n",
    "    result_cv['C_param'][splitN] = logreg_cv.cv_results_['params'][np.argmax(logreg_cv.cv_results_['split'+str(splitN)+'_test_score'])][\"C\"]\n",
    "result_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the model after CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model=LogisticRegression(C=logreg_cv.best_estimator_.C, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=4000,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=RANDOM_STATE, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.07196856730011521, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=4000, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=11, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add model to the result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Vectorizer_description</th>\n",
       "      <th>F1 train</th>\n",
       "      <th>F1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model   Preprocessing  \\\n",
       "1  LogisticRegression(C=0.07196856730011521, clas...  None-basemodel   \n",
       "\n",
       "                                          Vectorizer Vectorizer_description  \\\n",
       "1  CountVectorizer(analyzer='word', binary=False,...         None-basemodel   \n",
       "\n",
       "   F1 train   F1 test  \n",
       "1  0.965712  0.899145  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search_result = add_model_to_result_table(model_search_result, \n",
    "                                                baseline_model, \n",
    "                                                'None-basemodel', \n",
    "                                                count_vectorizer,\n",
    "                                                'None-basemodel',\n",
    "                                               f1_score(y_train, baseline_model.predict(X_train_features)),\n",
    "                                               f1_score(y_test, baseline_model.predict(X_test_features)))\n",
    "model_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Explore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuction for find out the samples with particular text\n",
    "def find_out_samples_with_text(data_for_explore, template):\n",
    "    return [review for review in data_for_explore['review'] if  template in review.lower()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepocessing\n",
    "#### The first step for preprocessing is remove html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing1 = 'Remove htmg tags'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    cleantext = re.sub(r'<br.*?>', ' ', raw_html)\n",
    "    return cleantext\n",
    "#   cleanr = re.compile('(<br >)|(<br />)|(\\b[Bb][Rr]\\b)|( [Bb][Rr] )')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prepoc_remove_tags = data.copy()\n",
    "data_prepoc_remove_tags['review'] = data_prepoc_remove_tags.apply(lambda x: cleanhtml(x['review']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_exploring(data_explor, preprocessing_explor, count_vectorizer_explor, count_vectorizer_description_explor):\n",
    "    #split data for train and test sets\n",
    "    X_explor = data_explor['review']\n",
    "    y_explor = data_explor['sentiment']\n",
    "    X_train_explor, X_test_explor, y_train_explor, y_test_explor = train_test_split(X_explor, y_explor, \n",
    "                                                                                        test_size=0.3, \n",
    "                                                                                        random_state=RANDOM_STATE, \n",
    "                                                                                        stratify = y_explor)\n",
    "  \n",
    "    \n",
    "    \n",
    "    # fit and transform on it the training features\n",
    "    count_vectorizer_explor.fit(X_train_explor)\n",
    "    X_train_features_explor = count_vectorizer_explor.transform(X_train_explor)\n",
    "    \n",
    "    #transform the test features to sparse matrix\n",
    "    X_test_features_explor = count_vectorizer_explor.transform(X_test_explor)\n",
    "    \n",
    "    model_explor = LogisticRegression(C=logreg_cv.best_estimator_.C, class_weight=None, \n",
    "                                                  dual=False, fit_intercept=True, intercept_scaling=1, \n",
    "                                                  l1_ratio=None, max_iter=4000, multi_class='auto', \n",
    "                                                  n_jobs=None, penalty='l2', random_state=RANDOM_STATE, \n",
    "                                                  solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "    model_explor.fit(X_train_features_explor, y_train_explor)\n",
    "    \n",
    "    return(add_model_to_result_table(model_search_result, \n",
    "                                     model_explor, \n",
    "                                     preprocessing_explor, \n",
    "                                     count_vectorizer_explor,\n",
    "                                     count_vectorizer_description_explor,\n",
    "                                     f1_score(y_train_explor, model_explor.predict(X_train_features_explor)),\n",
    "                                     f1_score(y_test_explor, model_explor.predict(X_test_features_explor)),\n",
    "                                    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Vectorizer_description</th>\n",
       "      <th>F1 train</th>\n",
       "      <th>F1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove htmg tags</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model     Preprocessing  \\\n",
       "1  LogisticRegression(C=0.07196856730011521, clas...    None-basemodel   \n",
       "2  LogisticRegression(C=0.07196856730011521, clas...  Remove htmg tags   \n",
       "\n",
       "                                          Vectorizer Vectorizer_description  \\\n",
       "1  CountVectorizer(analyzer='word', binary=False,...         None-basemodel   \n",
       "2  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "\n",
       "   F1 train   F1 test  \n",
       "1  0.965712  0.899145  \n",
       "2  0.965600  0.898945  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the baseline model with for data after preprocessing\n",
    "model_search_result = model_exploring(data_prepoc_remove_tags, preprocessing1, CountVectorizer(), 'None')\n",
    "model_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare vocabularies\n",
    "sorted(list(set(model_search_result['Vectorizer'][model_search_result['Preprocessing']=='None-basemodel'].iloc[0]\n",
    "                .get_feature_names())\n",
    "            .symmetric_difference(set(model_search_result['Vectorizer'][model_search_result['Preprocessing']=='Remove htmg tags'].iloc[0]\n",
    "                                      .get_feature_names()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The second step for preprocessing is remove duplicates ans incorrect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing2 = 'Remove duplicates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prepoc_remove_duplicates = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review\n",
       "count                                                 418\n",
       "unique                                                406\n",
       "top     Loved today's show!!! It was a variety and not...\n",
       "freq                                                    4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prepoc_remove_duplicates[data_prepoc_remove_duplicates.duplicated()].describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all duplicates rows, (indexes are ignored.)\n",
    "data_prepoc_remove_duplicates = data_prepoc_remove_duplicates.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>CyberTracker is set in Los Angeles sometime in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review\n",
       "count                                               49582\n",
       "unique                                              49582\n",
       "top     CyberTracker is set in Los Angeles sometime in...\n",
       "freq                                                    1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if we have only unique value of Review\n",
    "data_prepoc_remove_duplicates.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Vectorizer_description</th>\n",
       "      <th>F1 train</th>\n",
       "      <th>F1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove htmg tags</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove duplicates</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965288</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model      Preprocessing  \\\n",
       "1  LogisticRegression(C=0.07196856730011521, clas...     None-basemodel   \n",
       "2  LogisticRegression(C=0.07196856730011521, clas...   Remove htmg tags   \n",
       "3  LogisticRegression(C=0.07196856730011521, clas...  Remove duplicates   \n",
       "\n",
       "                                          Vectorizer Vectorizer_description  \\\n",
       "1  CountVectorizer(analyzer='word', binary=False,...         None-basemodel   \n",
       "2  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "3  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "\n",
       "   F1 train   F1 test  \n",
       "1  0.965712  0.899145  \n",
       "2  0.965600  0.898945  \n",
       "3  0.965288  0.894400  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the baseline model with for data after preprocessing\n",
    "model_search_result = model_exploring(data_prepoc_remove_duplicates, preprocessing2, CountVectorizer(), 'None')\n",
    "model_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The third step for preprocessing is remove digits from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing3_1 = 'Remove all digits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline vocabulary contains 1566 features with digits\n"
     ]
    }
   ],
   "source": [
    "#check vocabulary from baseline \n",
    "print('Baseline vocabulary contains ' +\n",
    "      str(len([feature_name for feature_name in count_vectorizer.get_feature_names() if re.match(r'.*\\d.*', feature_name)])) +\n",
    "     ' features with digits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstly try removing all digits\n",
    "def clean_all_digit(text):\n",
    "    cleantext = re.sub(r'\\d+', ' ', text)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare data \n",
    "data_prepoc_remove_all_digits = data.copy()\n",
    "data_prepoc_remove_all_digits['review'] = data_prepoc_remove_all_digits.apply(lambda x: clean_all_digit(x['review']), axis = 1)\n",
    "data_prepoc_remove_all_digits.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Vectorizer_description</th>\n",
       "      <th>F1 train</th>\n",
       "      <th>F1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove htmg tags</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove duplicates</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965288</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove all digits</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.964779</td>\n",
       "      <td>0.898965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model      Preprocessing  \\\n",
       "1  LogisticRegression(C=0.07196856730011521, clas...     None-basemodel   \n",
       "2  LogisticRegression(C=0.07196856730011521, clas...   Remove htmg tags   \n",
       "3  LogisticRegression(C=0.07196856730011521, clas...  Remove duplicates   \n",
       "4  LogisticRegression(C=0.07196856730011521, clas...  Remove all digits   \n",
       "\n",
       "                                          Vectorizer Vectorizer_description  \\\n",
       "1  CountVectorizer(analyzer='word', binary=False,...         None-basemodel   \n",
       "2  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "3  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "4  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "\n",
       "   F1 train   F1 test  \n",
       "1  0.965712  0.899145  \n",
       "2  0.965600  0.898945  \n",
       "3  0.965288  0.894400  \n",
       "4  0.964779  0.898965  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_search_result = model_exploring(data_prepoc_remove_all_digits, preprocessing3_1, CountVectorizer(), 'None') \n",
    "model_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline vocabulary contains 88087 features\n",
      "The vocabulary after remove all digits contains 86621 features\n"
     ]
    }
   ],
   "source": [
    "# compare vocabularies\n",
    "print('The baseline vocabulary contains ' + \n",
    "      str(len(model_search_result['Vectorizer'][model_search_result['Preprocessing']=='None-basemodel'].iloc[0]\n",
    "                .get_feature_names())) + \n",
    "     ' features')\n",
    "print('The vocabulary after remove all digits contains ' + \n",
    "      str(len(model_search_result['Vectorizer'][model_search_result['Preprocessing']=='Remove all digits'].iloc[0]\n",
    "                .get_feature_names())) + \n",
    "     ' features')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondly try splitting digits and letters\n",
    "preprocessing3_2 = 'Split digits with letters'\n",
    "\n",
    "def split_digit_letter(text):\n",
    "    cleantext = re.sub(r'(\\d+)', r' \\1 ', text)\n",
    "    cleantext = re.sub(r'_+', r' ', cleantext)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare data \n",
    "data_prepoc_split_digit_letter = data.copy()\n",
    "data_prepoc_split_digit_letter['review'] = data_prepoc_split_digit_letter.apply(lambda x: split_digit_letter(x['review']), axis = 1)\n",
    "data_prepoc_split_digit_letter.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Vectorizer_description</th>\n",
       "      <th>F1 train</th>\n",
       "      <th>F1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove htmg tags</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove duplicates</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965288</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove all digits</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.964779</td>\n",
       "      <td>0.898965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Split digits with letters</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.899159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  \\\n",
       "1  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "2  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "3  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "4  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "5  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "\n",
       "               Preprocessing  \\\n",
       "1             None-basemodel   \n",
       "2           Remove htmg tags   \n",
       "3          Remove duplicates   \n",
       "4          Remove all digits   \n",
       "5  Split digits with letters   \n",
       "\n",
       "                                          Vectorizer Vectorizer_description  \\\n",
       "1  CountVectorizer(analyzer='word', binary=False,...         None-basemodel   \n",
       "2  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "3  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "4  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "5  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "\n",
       "   F1 train   F1 test  \n",
       "1  0.965712  0.899145  \n",
       "2  0.965600  0.898945  \n",
       "3  0.965288  0.894400  \n",
       "4  0.964779  0.898965  \n",
       "5  0.965566  0.899159  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search_result = model_exploring(data_prepoc_split_digit_letter, preprocessing3_2, CountVectorizer(), 'None') \n",
    "model_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fourth step for preprocessing is replace words with the one form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing4_1 = 'Replace with correct form'\n",
    "\n",
    "def replace_word_with_correct_form(text):\n",
    "    cleantext = re.sub(r'(a+r+g+h+)', 'argh', text)\n",
    "    cleantext = re.sub(r'(a+h+g+)', 'ahg', cleantext)\n",
    "    cleantext = re.sub(r'(a+h+)', 'ah', cleantext)\n",
    "    cleantext = re.sub(r'(\\ba{2,})', 'a', cleantext)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data \n",
    "data_replace_word_with_correct_form = data.copy()\n",
    "data_replace_word_with_correct_form['review'] = data_replace_word_with_correct_form.apply(lambda x: replace_word_with_correct_form(x['review']), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Vectorizer_description</th>\n",
       "      <th>F1 train</th>\n",
       "      <th>F1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove htmg tags</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove duplicates</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965288</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove all digits</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.964779</td>\n",
       "      <td>0.898965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Split digits with letters</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.899159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Replace with correct form</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965682</td>\n",
       "      <td>0.899085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  \\\n",
       "1  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "2  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "3  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "4  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "5  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "6  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "\n",
       "               Preprocessing  \\\n",
       "1             None-basemodel   \n",
       "2           Remove htmg tags   \n",
       "3          Remove duplicates   \n",
       "4          Remove all digits   \n",
       "5  Split digits with letters   \n",
       "6  Replace with correct form   \n",
       "\n",
       "                                          Vectorizer Vectorizer_description  \\\n",
       "1  CountVectorizer(analyzer='word', binary=False,...         None-basemodel   \n",
       "2  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "3  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "4  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "5  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "6  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "\n",
       "   F1 train   F1 test  \n",
       "1  0.965712  0.899145  \n",
       "2  0.965600  0.898945  \n",
       "3  0.965288  0.894400  \n",
       "4  0.964779  0.898965  \n",
       "5  0.965566  0.899159  \n",
       "6  0.965682  0.899085  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search_result = model_exploring(data_replace_word_with_correct_form, preprocessing4_1, CountVectorizer(), 'None') \n",
    "model_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "#### The first step for vectorization is using n_gramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Vectorizer_description</th>\n",
       "      <th>F1 train</th>\n",
       "      <th>F1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove htmg tags</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove duplicates</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965288</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove all digits</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.964779</td>\n",
       "      <td>0.898965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Split digits with letters</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.899159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Replace with correct form</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965682</td>\n",
       "      <td>0.899085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(1,3)</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>0.909006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  \\\n",
       "1  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "2  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "3  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "4  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "5  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "6  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "7  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "\n",
       "               Preprocessing  \\\n",
       "1             None-basemodel   \n",
       "2           Remove htmg tags   \n",
       "3          Remove duplicates   \n",
       "4          Remove all digits   \n",
       "5  Split digits with letters   \n",
       "6  Replace with correct form   \n",
       "7                       None   \n",
       "\n",
       "                                          Vectorizer Vectorizer_description  \\\n",
       "1  CountVectorizer(analyzer='word', binary=False,...         None-basemodel   \n",
       "2  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "3  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "4  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "5  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "6  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "7  CountVectorizer(analyzer='word', binary=False,...      ngram_range=(1,3)   \n",
       "\n",
       "   F1 train   F1 test  \n",
       "1  0.965712  0.899145  \n",
       "2  0.965600  0.898945  \n",
       "3  0.965288  0.894400  \n",
       "4  0.964779  0.898965  \n",
       "5  0.965566  0.899159  \n",
       "6  0.965682  0.899085  \n",
       "7  0.999829  0.909006  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search_result = model_exploring(data, 'None', CountVectorizer(ngram_range=(1,3)), 'ngram_range=(1,3)') \n",
    "model_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Vectorizer_description</th>\n",
       "      <th>F1 train</th>\n",
       "      <th>F1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove htmg tags</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove duplicates</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965288</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove all digits</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.964779</td>\n",
       "      <td>0.898965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Split digits with letters</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.899159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Replace with correct form</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965682</td>\n",
       "      <td>0.899085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(1,3)</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>0.909006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(1,2)</td>\n",
       "      <td>0.998772</td>\n",
       "      <td>0.909564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  \\\n",
       "1  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "2  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "3  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "4  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "5  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "6  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "7  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "8  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "\n",
       "               Preprocessing  \\\n",
       "1             None-basemodel   \n",
       "2           Remove htmg tags   \n",
       "3          Remove duplicates   \n",
       "4          Remove all digits   \n",
       "5  Split digits with letters   \n",
       "6  Replace with correct form   \n",
       "7                       None   \n",
       "8                       None   \n",
       "\n",
       "                                          Vectorizer Vectorizer_description  \\\n",
       "1  CountVectorizer(analyzer='word', binary=False,...         None-basemodel   \n",
       "2  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "3  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "4  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "5  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "6  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "7  CountVectorizer(analyzer='word', binary=False,...      ngram_range=(1,3)   \n",
       "8  CountVectorizer(analyzer='word', binary=False,...      ngram_range=(1,2)   \n",
       "\n",
       "   F1 train   F1 test  \n",
       "1  0.965712  0.899145  \n",
       "2  0.965600  0.898945  \n",
       "3  0.965288  0.894400  \n",
       "4  0.964779  0.898965  \n",
       "5  0.965566  0.899159  \n",
       "6  0.965682  0.899085  \n",
       "7  0.999829  0.909006  \n",
       "8  0.998772  0.909564  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search_result = model_exploring(data, 'None', CountVectorizer(ngram_range=(1,2)), 'ngram_range=(1,2)') \n",
    "model_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Vectorizer_description</th>\n",
       "      <th>F1 train</th>\n",
       "      <th>F1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove htmg tags</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove duplicates</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965288</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove all digits</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.964779</td>\n",
       "      <td>0.898965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Split digits with letters</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.899159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Replace with correct form</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965682</td>\n",
       "      <td>0.899085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(1,3)</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>0.909006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(1,2)</td>\n",
       "      <td>0.998772</td>\n",
       "      <td>0.909564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(2,2)</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>0.891359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  \\\n",
       "1  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "2  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "3  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "4  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "5  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "6  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "7  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "8  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "9  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "\n",
       "               Preprocessing  \\\n",
       "1             None-basemodel   \n",
       "2           Remove htmg tags   \n",
       "3          Remove duplicates   \n",
       "4          Remove all digits   \n",
       "5  Split digits with letters   \n",
       "6  Replace with correct form   \n",
       "7                       None   \n",
       "8                       None   \n",
       "9                       None   \n",
       "\n",
       "                                          Vectorizer Vectorizer_description  \\\n",
       "1  CountVectorizer(analyzer='word', binary=False,...         None-basemodel   \n",
       "2  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "3  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "4  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "5  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "6  CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "7  CountVectorizer(analyzer='word', binary=False,...      ngram_range=(1,3)   \n",
       "8  CountVectorizer(analyzer='word', binary=False,...      ngram_range=(1,2)   \n",
       "9  CountVectorizer(analyzer='word', binary=False,...      ngram_range=(2,2)   \n",
       "\n",
       "   F1 train   F1 test  \n",
       "1  0.965712  0.899145  \n",
       "2  0.965600  0.898945  \n",
       "3  0.965288  0.894400  \n",
       "4  0.964779  0.898965  \n",
       "5  0.965566  0.899159  \n",
       "6  0.965682  0.899085  \n",
       "7  0.999829  0.909006  \n",
       "8  0.998772  0.909564  \n",
       "9  0.998515  0.891359  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search_result = model_exploring(data, 'None', CountVectorizer(ngram_range=(2,2)), 'ngram_range=(2,2)') \n",
    "model_search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The second step for vectorization is using the list Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Vectorizer_description</th>\n",
       "      <th>F1 train</th>\n",
       "      <th>F1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove htmg tags</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove duplicates</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965288</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove all digits</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.964779</td>\n",
       "      <td>0.898965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Split digits with letters</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.899159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Replace with correct form</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965682</td>\n",
       "      <td>0.899085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(1,3)</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>0.909006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(1,2)</td>\n",
       "      <td>0.998772</td>\n",
       "      <td>0.909564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(2,2)</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>0.891359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>stop_words=english</td>\n",
       "      <td>0.962234</td>\n",
       "      <td>0.891504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  \\\n",
       "1   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "2   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "3   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "4   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "5   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "6   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "7   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "8   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "9   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "10  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "\n",
       "                Preprocessing  \\\n",
       "1              None-basemodel   \n",
       "2            Remove htmg tags   \n",
       "3           Remove duplicates   \n",
       "4           Remove all digits   \n",
       "5   Split digits with letters   \n",
       "6   Replace with correct form   \n",
       "7                        None   \n",
       "8                        None   \n",
       "9                        None   \n",
       "10                       None   \n",
       "\n",
       "                                           Vectorizer Vectorizer_description  \\\n",
       "1   CountVectorizer(analyzer='word', binary=False,...         None-basemodel   \n",
       "2   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "3   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "4   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "5   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "6   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "7   CountVectorizer(analyzer='word', binary=False,...      ngram_range=(1,3)   \n",
       "8   CountVectorizer(analyzer='word', binary=False,...      ngram_range=(1,2)   \n",
       "9   CountVectorizer(analyzer='word', binary=False,...      ngram_range=(2,2)   \n",
       "10  CountVectorizer(analyzer='word', binary=False,...     stop_words=english   \n",
       "\n",
       "    F1 train   F1 test  \n",
       "1   0.965712  0.899145  \n",
       "2   0.965600  0.898945  \n",
       "3   0.965288  0.894400  \n",
       "4   0.964779  0.898965  \n",
       "5   0.965566  0.899159  \n",
       "6   0.965682  0.899085  \n",
       "7   0.999829  0.909006  \n",
       "8   0.998772  0.909564  \n",
       "9   0.998515  0.891359  \n",
       "10  0.962234  0.891504  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search_result = model_exploring(data, 'None', CountVectorizer(stop_words='english'), 'stop_words=english') \n",
    "model_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_search_result = model_search_result.drop([9,11,12,13,14], axis=0)\n",
    "# model_search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The third step for vectorization is limitation size of the vocabulary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Vectorizer_description</th>\n",
       "      <th>F1 train</th>\n",
       "      <th>F1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove htmg tags</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove duplicates</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965288</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove all digits</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.964779</td>\n",
       "      <td>0.898965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Split digits with letters</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.899159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Replace with correct form</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965682</td>\n",
       "      <td>0.899085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(1,3)</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>0.909006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(1,2)</td>\n",
       "      <td>0.998772</td>\n",
       "      <td>0.909564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(2,2)</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>0.891359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>stop_words=english</td>\n",
       "      <td>0.962234</td>\n",
       "      <td>0.891504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>max_features=50000</td>\n",
       "      <td>0.964551</td>\n",
       "      <td>0.898864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>max_features=75000</td>\n",
       "      <td>0.965374</td>\n",
       "      <td>0.899085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>max_features=80000</td>\n",
       "      <td>0.965458</td>\n",
       "      <td>0.899011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  \\\n",
       "1   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "2   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "3   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "4   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "5   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "6   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "7   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "8   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "9   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "10  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "11  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "12  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "13  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "\n",
       "                Preprocessing  \\\n",
       "1              None-basemodel   \n",
       "2            Remove htmg tags   \n",
       "3           Remove duplicates   \n",
       "4           Remove all digits   \n",
       "5   Split digits with letters   \n",
       "6   Replace with correct form   \n",
       "7                        None   \n",
       "8                        None   \n",
       "9                        None   \n",
       "10                       None   \n",
       "11                       None   \n",
       "12                       None   \n",
       "13                       None   \n",
       "\n",
       "                                           Vectorizer Vectorizer_description  \\\n",
       "1   CountVectorizer(analyzer='word', binary=False,...         None-basemodel   \n",
       "2   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "3   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "4   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "5   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "6   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "7   CountVectorizer(analyzer='word', binary=False,...      ngram_range=(1,3)   \n",
       "8   CountVectorizer(analyzer='word', binary=False,...      ngram_range=(1,2)   \n",
       "9   CountVectorizer(analyzer='word', binary=False,...      ngram_range=(2,2)   \n",
       "10  CountVectorizer(analyzer='word', binary=False,...     stop_words=english   \n",
       "11  CountVectorizer(analyzer='word', binary=False,...     max_features=50000   \n",
       "12  CountVectorizer(analyzer='word', binary=False,...     max_features=75000   \n",
       "13  CountVectorizer(analyzer='word', binary=False,...     max_features=80000   \n",
       "\n",
       "    F1 train   F1 test  \n",
       "1   0.965712  0.899145  \n",
       "2   0.965600  0.898945  \n",
       "3   0.965288  0.894400  \n",
       "4   0.964779  0.898965  \n",
       "5   0.965566  0.899159  \n",
       "6   0.965682  0.899085  \n",
       "7   0.999829  0.909006  \n",
       "8   0.998772  0.909564  \n",
       "9   0.998515  0.891359  \n",
       "10  0.962234  0.891504  \n",
       "11  0.964551  0.898864  \n",
       "12  0.965374  0.899085  \n",
       "13  0.965458  0.899011  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search_result = model_exploring(data, 'None', CountVectorizer(max_features=50000), 'max_features=50000') \n",
    "model_search_result = model_exploring(data, 'None', CountVectorizer(max_features=75000), 'max_features=75000') \n",
    "model_search_result = model_exploring(data, 'None', CountVectorizer(max_features=80000), 'max_features=80000') \n",
    "model_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fourth step is min_df and max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Vectorizer_description</th>\n",
       "      <th>F1 train</th>\n",
       "      <th>F1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove htmg tags</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove duplicates</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965288</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove all digits</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.964779</td>\n",
       "      <td>0.898965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Split digits with letters</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.899159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Replace with correct form</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965682</td>\n",
       "      <td>0.899085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(1,3)</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>0.909006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(1,2)</td>\n",
       "      <td>0.998772</td>\n",
       "      <td>0.909564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(2,2)</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>0.891359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>stop_words=english</td>\n",
       "      <td>0.962234</td>\n",
       "      <td>0.891504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>max_features=50000</td>\n",
       "      <td>0.964551</td>\n",
       "      <td>0.898864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>max_features=75000</td>\n",
       "      <td>0.965374</td>\n",
       "      <td>0.899085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>max_features=80000</td>\n",
       "      <td>0.965458</td>\n",
       "      <td>0.899011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>min_df=50</td>\n",
       "      <td>0.943223</td>\n",
       "      <td>0.892226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>min_df=200</td>\n",
       "      <td>0.916161</td>\n",
       "      <td>0.887465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>max_df=0.99</td>\n",
       "      <td>0.965562</td>\n",
       "      <td>0.898624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>max_df=0.9999</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  \\\n",
       "1   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "2   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "3   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "4   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "5   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "6   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "7   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "8   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "9   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "10  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "11  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "12  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "13  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "14  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "15  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "16  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "17  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "\n",
       "                Preprocessing  \\\n",
       "1              None-basemodel   \n",
       "2            Remove htmg tags   \n",
       "3           Remove duplicates   \n",
       "4           Remove all digits   \n",
       "5   Split digits with letters   \n",
       "6   Replace with correct form   \n",
       "7                        None   \n",
       "8                        None   \n",
       "9                        None   \n",
       "10                       None   \n",
       "11                       None   \n",
       "12                       None   \n",
       "13                       None   \n",
       "14                       None   \n",
       "15                       None   \n",
       "16                       None   \n",
       "17                       None   \n",
       "\n",
       "                                           Vectorizer Vectorizer_description  \\\n",
       "1   CountVectorizer(analyzer='word', binary=False,...         None-basemodel   \n",
       "2   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "3   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "4   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "5   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "6   CountVectorizer(analyzer='word', binary=False,...                   None   \n",
       "7   CountVectorizer(analyzer='word', binary=False,...      ngram_range=(1,3)   \n",
       "8   CountVectorizer(analyzer='word', binary=False,...      ngram_range=(1,2)   \n",
       "9   CountVectorizer(analyzer='word', binary=False,...      ngram_range=(2,2)   \n",
       "10  CountVectorizer(analyzer='word', binary=False,...     stop_words=english   \n",
       "11  CountVectorizer(analyzer='word', binary=False,...     max_features=50000   \n",
       "12  CountVectorizer(analyzer='word', binary=False,...     max_features=75000   \n",
       "13  CountVectorizer(analyzer='word', binary=False,...     max_features=80000   \n",
       "14  CountVectorizer(analyzer='word', binary=False,...              min_df=50   \n",
       "15  CountVectorizer(analyzer='word', binary=False,...             min_df=200   \n",
       "16  CountVectorizer(analyzer='word', binary=False,...            max_df=0.99   \n",
       "17  CountVectorizer(analyzer='word', binary=False,...          max_df=0.9999   \n",
       "\n",
       "    F1 train   F1 test  \n",
       "1   0.965712  0.899145  \n",
       "2   0.965600  0.898945  \n",
       "3   0.965288  0.894400  \n",
       "4   0.964779  0.898965  \n",
       "5   0.965566  0.899159  \n",
       "6   0.965682  0.899085  \n",
       "7   0.999829  0.909006  \n",
       "8   0.998772  0.909564  \n",
       "9   0.998515  0.891359  \n",
       "10  0.962234  0.891504  \n",
       "11  0.964551  0.898864  \n",
       "12  0.965374  0.899085  \n",
       "13  0.965458  0.899011  \n",
       "14  0.943223  0.892226  \n",
       "15  0.916161  0.887465  \n",
       "16  0.965562  0.898624  \n",
       "17  0.965712  0.899145  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_search_result = model_exploring(data, 'None', CountVectorizer(min_df=50), 'min_df=50')\n",
    "model_search_result = model_exploring(data, 'None', CountVectorizer(min_df=200), 'min_df=200')\n",
    "model_search_result = model_exploring(data, 'None', CountVectorizer(max_df=0.99), 'max_df=0.99')\n",
    "model_search_result = model_exploring(data, 'None', CountVectorizer(max_df=0.9999), 'max_df=0.9999')\n",
    "model_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply TfidfVectorizer with parameters:\n",
    "smooth_idfbool = False, in our set the situation when an extra document was seen containing every term in the collection exactly once is unlikely.\n",
    "sublinear_tf=True, replace tf with 1 + log(tf).(this parameter might be used for gridSearch)\n",
    "norm=None, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Vectorizer_description</th>\n",
       "      <th>F1 train</th>\n",
       "      <th>F1 test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None-basemodel</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove htmg tags</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.898945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove duplicates</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965288</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Remove all digits</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.964779</td>\n",
       "      <td>0.898965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Split digits with letters</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.899159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Replace with correct form</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.965682</td>\n",
       "      <td>0.899085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(1,3)</td>\n",
       "      <td>0.999829</td>\n",
       "      <td>0.909006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(1,2)</td>\n",
       "      <td>0.998772</td>\n",
       "      <td>0.909564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>ngram_range=(2,2)</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>0.891359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>stop_words=english</td>\n",
       "      <td>0.962234</td>\n",
       "      <td>0.891504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>max_features=50000</td>\n",
       "      <td>0.964551</td>\n",
       "      <td>0.898864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>max_features=75000</td>\n",
       "      <td>0.965374</td>\n",
       "      <td>0.899085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>max_features=80000</td>\n",
       "      <td>0.965458</td>\n",
       "      <td>0.899011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>min_df=50</td>\n",
       "      <td>0.943223</td>\n",
       "      <td>0.892226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>min_df=200</td>\n",
       "      <td>0.916161</td>\n",
       "      <td>0.887465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>max_df=0.99</td>\n",
       "      <td>0.965562</td>\n",
       "      <td>0.898624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>None</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>max_df=0.9999</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.899145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression(C=0.07196856730011521, clas...</td>\n",
       "      <td>Split digits with letters</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer, ngram_range=(1,2)\\n smooth_id...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  \\\n",
       "1   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "2   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "3   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "4   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "5   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "6   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "7   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "8   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "9   LogisticRegression(C=0.07196856730011521, clas...   \n",
       "10  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "11  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "12  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "13  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "14  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "15  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "16  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "17  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "18  LogisticRegression(C=0.07196856730011521, clas...   \n",
       "\n",
       "                Preprocessing  \\\n",
       "1              None-basemodel   \n",
       "2            Remove htmg tags   \n",
       "3           Remove duplicates   \n",
       "4           Remove all digits   \n",
       "5   Split digits with letters   \n",
       "6   Replace with correct form   \n",
       "7                        None   \n",
       "8                        None   \n",
       "9                        None   \n",
       "10                       None   \n",
       "11                       None   \n",
       "12                       None   \n",
       "13                       None   \n",
       "14                       None   \n",
       "15                       None   \n",
       "16                       None   \n",
       "17                       None   \n",
       "18  Split digits with letters   \n",
       "\n",
       "                                           Vectorizer  \\\n",
       "1   CountVectorizer(analyzer='word', binary=False,...   \n",
       "2   CountVectorizer(analyzer='word', binary=False,...   \n",
       "3   CountVectorizer(analyzer='word', binary=False,...   \n",
       "4   CountVectorizer(analyzer='word', binary=False,...   \n",
       "5   CountVectorizer(analyzer='word', binary=False,...   \n",
       "6   CountVectorizer(analyzer='word', binary=False,...   \n",
       "7   CountVectorizer(analyzer='word', binary=False,...   \n",
       "8   CountVectorizer(analyzer='word', binary=False,...   \n",
       "9   CountVectorizer(analyzer='word', binary=False,...   \n",
       "10  CountVectorizer(analyzer='word', binary=False,...   \n",
       "11  CountVectorizer(analyzer='word', binary=False,...   \n",
       "12  CountVectorizer(analyzer='word', binary=False,...   \n",
       "13  CountVectorizer(analyzer='word', binary=False,...   \n",
       "14  CountVectorizer(analyzer='word', binary=False,...   \n",
       "15  CountVectorizer(analyzer='word', binary=False,...   \n",
       "16  CountVectorizer(analyzer='word', binary=False,...   \n",
       "17  CountVectorizer(analyzer='word', binary=False,...   \n",
       "18  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "\n",
       "                               Vectorizer_description  F1 train   F1 test  \n",
       "1                                      None-basemodel  0.965712  0.899145  \n",
       "2                                                None  0.965600  0.898945  \n",
       "3                                                None  0.965288  0.894400  \n",
       "4                                                None  0.964779  0.898965  \n",
       "5                                                None  0.965566  0.899159  \n",
       "6                                                None  0.965682  0.899085  \n",
       "7                                   ngram_range=(1,3)  0.999829  0.909006  \n",
       "8                                   ngram_range=(1,2)  0.998772  0.909564  \n",
       "9                                   ngram_range=(2,2)  0.998515  0.891359  \n",
       "10                                 stop_words=english  0.962234  0.891504  \n",
       "11                                 max_features=50000  0.964551  0.898864  \n",
       "12                                 max_features=75000  0.965374  0.899085  \n",
       "13                                 max_features=80000  0.965458  0.899011  \n",
       "14                                          min_df=50  0.943223  0.892226  \n",
       "15                                         min_df=200  0.916161  0.887465  \n",
       "16                                        max_df=0.99  0.965562  0.898624  \n",
       "17                                      max_df=0.9999  0.965712  0.899145  \n",
       "18  TfidfVectorizer, ngram_range=(1,2)\\n smooth_id...  1.000000  0.917421  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search_result = model_exploring(data_prepoc_split_digit_letter,\n",
    "                                      preprocessing3_2, \n",
    "                                      TfidfVectorizer(ngram_range=(1,2), smooth_idf=False, sublinear_tf=True, norm=None, ), \n",
    "                                      'TfidfVectorizer, ngram_range=(1,2)\\n smooth_idf=False, sublinear_tf=True, norm=None,') \n",
    "model_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the preprocessing steps and the best vectorizer  for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for training set 1.0\n",
      "f1 score for testing set 0.9103484969406758\n"
     ]
    }
   ],
   "source": [
    "#clean data\n",
    "data_cleaned = data.copy()\n",
    "data_cleaned = data_cleaned.drop_duplicates()\n",
    "data_cleaned['review'] = data_cleaned['review'].apply(lambda x: cleanhtml(split_digit_letter(x)))\n",
    "data_cleaned.head(5)\n",
    "\n",
    "X_cleaned = data_cleaned['review']\n",
    "y_cleaned = data_cleaned['sentiment']\n",
    "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(X_cleaned,\n",
    "                                                                                    y_cleaned,\n",
    "                                                                                    test_size=0.3,\n",
    "                                                                                    random_state=RANDOM_STATE,\n",
    "                                                                                    stratify = y_cleaned)\n",
    "  \n",
    "    \n",
    "    \n",
    "# fit and transform on it the training features\n",
    "tf_idf_vectorizer_cleaned = TfidfVectorizer(smooth_idf=False, sublinear_tf=True, norm=None, ngram_range=(1,2))\n",
    "tf_idf_vectorizer_cleaned.fit(X_train_cleaned)\n",
    "\n",
    "X_train_features_tf_idf_cleaned = tf_idf_vectorizer_cleaned.transform(X_train_cleaned)\n",
    "    \n",
    "#transform the test features to sparse matrix\n",
    "X_test_features_tf_idf_cleaned = tf_idf_vectorizer_cleaned.transform(X_test_cleaned)\n",
    "    \n",
    "model_tf_idf_cleaned = LogisticRegression(C=logreg_cv.best_estimator_.C, class_weight=None, \n",
    "                                                  dual=False, fit_intercept=True, intercept_scaling=1, \n",
    "                                                  l1_ratio=None, max_iter=4000, multi_class='auto', \n",
    "                                                  n_jobs=None, penalty='l2', random_state=RANDOM_STATE, \n",
    "                                                  solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "model_tf_idf_cleaned.fit(X_train_features_tf_idf_cleaned, y_train_cleaned)\n",
    "print('f1 score for training set ' + str(f1_score(y_train_cleaned, model_tf_idf_cleaned.predict(X_train_features_tf_idf_cleaned))))\n",
    "print('f1 score for testing set ' + str(f1_score(y_test_cleaned, model_tf_idf_cleaned.predict(X_test_features_tf_idf_cleaned))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_f1_curve(model_search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
