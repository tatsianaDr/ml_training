{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries & data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition constants\n",
    "RANDOM_STATE = 11\n",
    "MAX_ITER=4000\n",
    "NUMBER_K_FOLD = 5\n",
    "TARGET_METRIC = 'f1'\n",
    "TEST_SIZE = 0.3\n",
    "N_JOBS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for display dataframe\n",
    "pd.set_option('precision', 4)\n",
    "pd.set_option('max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen- Michael Sheen not only \"has got all the pola...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br /&gt;&lt;br /&gt;OK, first of all when you're going t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. &lt;br /&gt;&lt;br /&gt;This being a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job. It wasn't as creative or original as the first, but who was expecting it to be. It was a whole lotta fun. the more i think about it the more i like it, and when it comes out on DVD I'm going to pay the money for it very proudly, every last cent. Sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic directing, the annoying porn groove soundtrack that ran continually over the overacted script, and a crappy copy of the VHS cannot be redeemed by consuming liquor. Trust me, because I stuck this turkey out to the end. It was so pathetically bad all ove...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary schools by nuns, taught by Jesuit priests in high school &amp; college. I am still a practicing Catholic but would not be considered a \"good Catholic\" in the church's eyes because I don't believe certain things or act certain ways just because the churc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previous comment and side with Maltin on this one. This is a second rate, excessively vicious Western that creaks and groans trying to put across its central theme of the Wild West being tamed and kicked aside by the steady march of time. It would like to b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high art, but the fans do expect a movie that is as good as some of the best episodes. Unfortunately, this movie had a muddled, implausible plot that just left me cringing - this is by far the worst of the nine (so far) movies. Even the chance to watch t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                            review  \\\n",
       "0      One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO....   \n",
       "1      A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the pola...   \n",
       "2      I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may...   \n",
       "3      Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going t...   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a...   \n",
       "...                                                                                                                                                                                                                                                                                                            ...   \n",
       "49995  I thought this movie did a down right good job. It wasn't as creative or original as the first, but who was expecting it to be. It was a whole lotta fun. the more i think about it the more i like it, and when it comes out on DVD I'm going to pay the money for it very proudly, every last cent. Sh...   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic directing, the annoying porn groove soundtrack that ran continually over the overacted script, and a crappy copy of the VHS cannot be redeemed by consuming liquor. Trust me, because I stuck this turkey out to the end. It was so pathetically bad all ove...   \n",
       "49997  I am a Catholic taught in parochial elementary schools by nuns, taught by Jesuit priests in high school & college. I am still a practicing Catholic but would not be considered a \"good Catholic\" in the church's eyes because I don't believe certain things or act certain ways just because the churc...   \n",
       "49998  I'm going to have to disagree with the previous comment and side with Maltin on this one. This is a second rate, excessively vicious Western that creaks and groans trying to put across its central theme of the Wild West being tamed and kicked aside by the steady march of time. It would like to b...   \n",
       "49999  No one expects the Star Trek movies to be high art, but the fans do expect a movie that is as good as some of the best episodes. Unfortunately, this movie had a muddled, implausible plot that just left me cringing - this is by far the worst of the nine (so far) movies. Even the chance to watch t...   \n",
       "\n",
       "       sentiment  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              0  \n",
       "4              1  \n",
       "...          ...  \n",
       "49995          1  \n",
       "49996          0  \n",
       "49997          0  \n",
       "49998          0  \n",
       "49999          0  \n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import & display data\n",
    "data = pd.read_csv('data/IMDB_Dataset.csv')\n",
    "data['sentiment'] = data['sentiment'].replace({'positive' : 1, 'negative' : 0})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preprocessing\n",
    "\n",
    "def clean_html(data_: tuple):\n",
    "    data_new = data_[0].copy()\n",
    "    data_new = data_new.apply(lambda x: re.sub(r'<br.*?>', ' ', x))\n",
    "    return (data_new, data_[1])\n",
    "\n",
    "def remove_duplicates(data_: tuple):\n",
    "    data_new = pd.DataFrame(columns=['X', 'y'])\n",
    "    data_new.X, data_new.y = data_ \n",
    "    data_new = data_new.drop_duplicates()\n",
    "    return (data_new.X, data_new.y)\n",
    "\n",
    "def split_digit_letters(data_: tuple):\n",
    "    data_new = data_[0].copy()\n",
    "    data_new = data_new.apply(lambda x: re.sub(r'(\\d+)', r' \\1 ', x))\n",
    "    data_new = data_new.apply(lambda x: re.sub(r'_+', r' ', x))\n",
    "    return (data_new, data_[1])\n",
    "\n",
    "\n",
    "def preprocessing(data_: tuple):\n",
    "    return clean_html(remove_duplicates(split_digit_letters(data_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepocessing  data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_train = preprocessing((data.review, data.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_for_train[0]\n",
    "y = data_for_train[1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=TEST_SIZE, \n",
    "                                                    random_state=RANDOM_STATE, \n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_and_evaluate(pipeline, params_grid):\n",
    "    grid_cv = GridSearchCV(pipeline, cv=NUMBER_K_FOLD, n_jobs=N_JOBS, param_grid=params_grid, scoring=TARGET_METRIC, \n",
    "                            return_train_score=False, verbose=5)\n",
    "    grid_cv.fit(X_train, y_train)\n",
    "    model = grid_cv.best_estimator_\n",
    "    model.fit(X_train, y_train)\n",
    "    f1_cv = grid_cv.best_score_\n",
    "    f1_test = f1_score(model.predict(X_test), y_test)\n",
    "    result = {'grid_cv': grid_cv,\n",
    "             'model': model,\n",
    "             'f1_cv': f1_cv,\n",
    "             'f1_test': f1_test}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's evaluate the perfomance different types of models:\n",
    "    - Support Vector Machines\n",
    "    - Naive Bayes\n",
    "    - Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic regression \n",
    "Logistic regression is baseline model for this research. In the previous stage has been selected follow model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  5.6min remaining:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'grid_cv': GridSearchCV(cv=5, error_score=nan,\n",
       "              estimator=Pipeline(memory=None,\n",
       "                                 steps=[('vect',\n",
       "                                         TfidfVectorizer(analyzer='word',\n",
       "                                                         binary=False,\n",
       "                                                         decode_error='strict',\n",
       "                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                         encoding='utf-8',\n",
       "                                                         input='content',\n",
       "                                                         lowercase=True,\n",
       "                                                         max_df=1.0,\n",
       "                                                         max_features=None,\n",
       "                                                         min_df=1,\n",
       "                                                         ngram_range=(1, 1),\n",
       "                                                         norm='l2',\n",
       "                                                         preprocessor=None,\n",
       "                                                         smooth_idf=True,\n",
       "                                                         stop_words=None,\n",
       "                                                         strip_acce...\n",
       "                                                            max_iter=100,\n",
       "                                                            multi_class='auto',\n",
       "                                                            n_jobs=None,\n",
       "                                                            penalty='l2',\n",
       "                                                            random_state=None,\n",
       "                                                            solver='lbfgs',\n",
       "                                                            tol=0.0001,\n",
       "                                                            verbose=0,\n",
       "                                                            warm_start=False))],\n",
       "                                 verbose=False),\n",
       "              iid='deprecated', n_jobs=-1,\n",
       "              param_grid={'clf__C': [10000], 'clf__max_iter': [4000],\n",
       "                          'clf__random_state': [11],\n",
       "                          'vect__ngram_range': [(1, 2)]},\n",
       "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "              scoring='f1', verbose=1),\n",
       " 'model': Pipeline(memory=None,\n",
       "          steps=[('vect',\n",
       "                  TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                  decode_error='strict',\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  encoding='utf-8', input='content',\n",
       "                                  lowercase=True, max_df=1.0, max_features=None,\n",
       "                                  min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                  preprocessor=None, smooth_idf=True,\n",
       "                                  stop_words=None, strip_accents=None,\n",
       "                                  sublinear_tf=False,\n",
       "                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                  tokenizer=None, use_idf=True,\n",
       "                                  vocabulary=None)),\n",
       "                 ('clf',\n",
       "                  LogisticRegression(C=10000, class_weight=None, dual=False,\n",
       "                                     fit_intercept=True, intercept_scaling=1,\n",
       "                                     l1_ratio=None, max_iter=4000,\n",
       "                                     multi_class='auto', n_jobs=None,\n",
       "                                     penalty='l2', random_state=11,\n",
       "                                     solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                     warm_start=False))],\n",
       "          verbose=False),\n",
       " 'f1_cv': 0.9152489824029256,\n",
       " 'f1_test': 0.9127052722558341}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lr = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "\n",
    "params_lr ={\n",
    "    'vect__ngram_range': [(1,2)], \n",
    "    'clf__C':[10000], \n",
    "    'clf__max_iter': [MAX_ITER],\n",
    "    'clf__random_state': [RANDOM_STATE],\n",
    "           }\n",
    "\n",
    "lr_result = model_fit_and_evaluate(pipeline_lr, params_lr)\n",
    "\n",
    "lr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'grid_cv': GridSearchCV(cv=5, error_score=nan,\n",
       "              estimator=Pipeline(memory=None,\n",
       "                                 steps=[('vect',\n",
       "                                         TfidfVectorizer(analyzer='word',\n",
       "                                                         binary=False,\n",
       "                                                         decode_error='strict',\n",
       "                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                         encoding='utf-8',\n",
       "                                                         input='content',\n",
       "                                                         lowercase=True,\n",
       "                                                         max_df=1.0,\n",
       "                                                         max_features=None,\n",
       "                                                         min_df=1,\n",
       "                                                         ngram_range=(1, 1),\n",
       "                                                         norm='l2',\n",
       "                                                         preprocessor=None,\n",
       "                                                         smooth_idf=True,\n",
       "                                                         stop_words=None,\n",
       "                                                         strip_acce...\n",
       "                                                         tokenizer=None,\n",
       "                                                         use_idf=True,\n",
       "                                                         vocabulary=None)),\n",
       "                                        ('clf',\n",
       "                                         MultinomialNB(alpha=1.0,\n",
       "                                                       class_prior=None,\n",
       "                                                       fit_prior=True))],\n",
       "                                 verbose=False),\n",
       "              iid='deprecated', n_jobs=-1,\n",
       "              param_grid={'clf__alpha': [1, 0.1, 0.01, 0.001, 0.0001, 1e-05,\n",
       "                                         1e-06, 1e-07, 1e-08, 1e-09, 1e-10],\n",
       "                          'vect__ngram_range': [(1, 2)]},\n",
       "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "              scoring='f1', verbose=1),\n",
       " 'model': Pipeline(memory=None,\n",
       "          steps=[('vect',\n",
       "                  TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                  decode_error='strict',\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  encoding='utf-8', input='content',\n",
       "                                  lowercase=True, max_df=1.0, max_features=None,\n",
       "                                  min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                  preprocessor=None, smooth_idf=True,\n",
       "                                  stop_words=None, strip_accents=None,\n",
       "                                  sublinear_tf=False,\n",
       "                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                  tokenizer=None, use_idf=True,\n",
       "                                  vocabulary=None)),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))],\n",
       "          verbose=False),\n",
       " 'f1_cv': 0.891422262034807,\n",
       " 'f1_test': 0.890890756302521}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_nb = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "\n",
    "params_nb ={\n",
    "    'vect__ngram_range': [(1,2)], \n",
    "    'clf__alpha': [1, 0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06, 1e-07, 1e-08, 1e-09, 1.0e-10], \n",
    "           }\n",
    "\n",
    "nb_result = model_fit_and_evaluate(pipeline_nb, params_nb)\n",
    "nb_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 768 candidates, totalling 3840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 37.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 107.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 290.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 473.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 744.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 954.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 1276.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3840 out of 3840 | elapsed: 1599.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'grid_cv': GridSearchCV(cv=5, error_score=nan,\n",
       "              estimator=Pipeline(memory=None,\n",
       "                                 steps=[('vect',\n",
       "                                         TfidfVectorizer(analyzer='word',\n",
       "                                                         binary=False,\n",
       "                                                         decode_error='strict',\n",
       "                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                         encoding='utf-8',\n",
       "                                                         input='content',\n",
       "                                                         lowercase=True,\n",
       "                                                         max_df=1.0,\n",
       "                                                         max_features=None,\n",
       "                                                         min_df=1,\n",
       "                                                         ngram_range=(1, 1),\n",
       "                                                         norm='l2',\n",
       "                                                         preprocessor=None,\n",
       "                                                         smooth_idf=True,\n",
       "                                                         stop_words=None,\n",
       "                                                         strip_acce...\n",
       "              iid='deprecated', n_jobs=-1,\n",
       "              param_grid={'clf__class_weight': ['balanced', None],\n",
       "                          'clf__criterion': ['gini', 'entropy'],\n",
       "                          'clf__max_depth': [9, 10, 13, 15, 20, 40, 60, 100],\n",
       "                          'clf__min_samples_leaf': [9, 10, 11, 12],\n",
       "                          'clf__min_samples_split': [2, 5, 10, 20, 30, 40],\n",
       "                          'clf__random_state': [11],\n",
       "                          'vect__ngram_range': [(1, 2)]},\n",
       "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "              scoring='f1', verbose=1),\n",
       " 'model': Pipeline(memory=None,\n",
       "          steps=[('vect',\n",
       "                  TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                  decode_error='strict',\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  encoding='utf-8', input='content',\n",
       "                                  lowercase=True, max_df=1.0, max_features=None,\n",
       "                                  min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                  preprocessor=None, smooth_idf=True,\n",
       "                                  stop_words=None, strip_accents=None,\n",
       "                                  sublinear_tf=False,\n",
       "                                  token_pattern='(...\n",
       "                                  tokenizer=None, use_idf=True,\n",
       "                                  vocabulary=None)),\n",
       "                 ('clf',\n",
       "                  DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                         criterion='gini', max_depth=13,\n",
       "                                         max_features=None, max_leaf_nodes=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=9,\n",
       "                                         min_samples_split=20,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         presort='deprecated', random_state=11,\n",
       "                                         splitter='best'))],\n",
       "          verbose=False),\n",
       " 'f1_cv': 0.7514137416440401,\n",
       " 'f1_test': 0.7539446169444267}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_dt = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "\n",
    "params_dt ={\n",
    "    'vect__ngram_range': [(1,2)], \n",
    "    'clf__criterion':['gini', 'entropy'], \n",
    "    'clf__min_samples_split':[2, 5, 10, 20, 30, 40], \n",
    "    'clf__min_samples_leaf': [9,10,11,12],\n",
    "    'clf__max_depth': [9,10,13,15,20,40,60,100],\n",
    "    'clf__class_weight':['balanced', None],\n",
    "    'clf__random_state': [RANDOM_STATE],\n",
    "           }\n",
    "\n",
    "dt_result = model_fit_and_evaluate(pipeline_dt, params_dt)\n",
    "dt_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 383.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'grid_cv': GridSearchCV(cv=5, error_score=nan,\n",
       "              estimator=Pipeline(memory=None,\n",
       "                                 steps=[('vect',\n",
       "                                         TfidfVectorizer(analyzer='word',\n",
       "                                                         binary=False,\n",
       "                                                         decode_error='strict',\n",
       "                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                         encoding='utf-8',\n",
       "                                                         input='content',\n",
       "                                                         lowercase=True,\n",
       "                                                         max_df=1.0,\n",
       "                                                         max_features=None,\n",
       "                                                         min_df=1,\n",
       "                                                         ngram_range=(1, 1),\n",
       "                                                         norm='l2',\n",
       "                                                         preprocessor=None,\n",
       "                                                         smooth_idf=True,\n",
       "                                                         stop_words=None,\n",
       "                                                         strip_acce...\n",
       "                                             kernel='rbf', max_iter=-1,\n",
       "                                             probability=False,\n",
       "                                             random_state=None, shrinking=True,\n",
       "                                             tol=0.001, verbose=False))],\n",
       "                                 verbose=False),\n",
       "              iid='deprecated', n_jobs=-1,\n",
       "              param_grid={'clf__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                          'clf__kernel': ['linear'], 'clf__random_state': [11],\n",
       "                          'vect__ngram_range': [(1, 2)]},\n",
       "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "              scoring='f1', verbose=1),\n",
       " 'model': Pipeline(memory=None,\n",
       "          steps=[('vect',\n",
       "                  TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                  decode_error='strict',\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  encoding='utf-8', input='content',\n",
       "                                  lowercase=True, max_df=1.0, max_features=None,\n",
       "                                  min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                  preprocessor=None, smooth_idf=True,\n",
       "                                  stop_words=None, strip_accents=None,\n",
       "                                  sublinear_tf=False,\n",
       "                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                  tokenizer=None, use_idf=True,\n",
       "                                  vocabulary=None)),\n",
       "                 ('clf',\n",
       "                  SVC(C=10, break_ties=False, cache_size=200, class_weight=None,\n",
       "                      coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                      gamma='scale', kernel='linear', max_iter=-1,\n",
       "                      probability=False, random_state=11, shrinking=True,\n",
       "                      tol=0.001, verbose=False))],\n",
       "          verbose=False),\n",
       " 'f1_cv': 0.9157149482424265,\n",
       " 'f1_test': 0.9126265316995205}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_svm = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', svm.SVC()),\n",
    "])\n",
    "\n",
    "\n",
    "params_svm_lin ={\n",
    "    'vect__ngram_range': [(1,2)],  \n",
    "    'clf__kernel': ['linear'], \n",
    "    'clf__C': [0.0001,0.001,0.01,0.1,1,10,100, 1000],\n",
    "    'clf__random_state': [RANDOM_STATE],\n",
    "           }\n",
    "\n",
    "svm_result_lin = model_fit_and_evaluate(pipeline_svm, params_svm_lin)\n",
    "svm_result_lin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed: 147.9min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed: 319.0min remaining: 179.4min\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed: 471.8min remaining: 64.3min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed: 573.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'grid_cv': GridSearchCV(cv=5, error_score=nan,\n",
       "              estimator=Pipeline(memory=None,\n",
       "                                 steps=[('vect',\n",
       "                                         TfidfVectorizer(analyzer='word',\n",
       "                                                         binary=False,\n",
       "                                                         decode_error='strict',\n",
       "                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                         encoding='utf-8',\n",
       "                                                         input='content',\n",
       "                                                         lowercase=True,\n",
       "                                                         max_df=1.0,\n",
       "                                                         max_features=None,\n",
       "                                                         min_df=1,\n",
       "                                                         ngram_range=(1, 1),\n",
       "                                                         norm='l2',\n",
       "                                                         preprocessor=None,\n",
       "                                                         smooth_idf=True,\n",
       "                                                         stop_words=None,\n",
       "                                                         strip_acce...\n",
       "                                             degree=3, gamma='scale',\n",
       "                                             kernel='rbf', max_iter=-1,\n",
       "                                             probability=False,\n",
       "                                             random_state=None, shrinking=True,\n",
       "                                             tol=0.001, verbose=False))],\n",
       "                                 verbose=False),\n",
       "              iid='deprecated', n_jobs=-1,\n",
       "              param_grid={'clf__degree': [2, 3, 4, 5, 6],\n",
       "                          'clf__kernel': ['poly'], 'clf__random_state': [11],\n",
       "                          'vect__ngram_range': [(1, 2)]},\n",
       "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "              scoring='f1', verbose=5),\n",
       " 'model': Pipeline(memory=None,\n",
       "          steps=[('vect',\n",
       "                  TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                  decode_error='strict',\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  encoding='utf-8', input='content',\n",
       "                                  lowercase=True, max_df=1.0, max_features=None,\n",
       "                                  min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                  preprocessor=None, smooth_idf=True,\n",
       "                                  stop_words=None, strip_accents=None,\n",
       "                                  sublinear_tf=False,\n",
       "                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                  tokenizer=None, use_idf=True,\n",
       "                                  vocabulary=None)),\n",
       "                 ('clf',\n",
       "                  SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                      coef0=0.0, decision_function_shape='ovr', degree=2,\n",
       "                      gamma='scale', kernel='poly', max_iter=-1,\n",
       "                      probability=False, random_state=11, shrinking=True,\n",
       "                      tol=0.001, verbose=False))],\n",
       "          verbose=False),\n",
       " 'f1_cv': 0.8855069211381223,\n",
       " 'f1_test': 0.8864950078822911}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_svm = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', svm.SVC()),\n",
    "])\n",
    "\n",
    "\n",
    "params_svm_poly ={\n",
    "    'vect__ngram_range': [(1,2)],  \n",
    "    'clf__kernel': ['poly'], \n",
    "    'clf__degree': [2,3,4,5,6],\n",
    "    'clf__random_state': [RANDOM_STATE],\n",
    "           }\n",
    "\n",
    "svm_result_poly = model_fit_and_evaluate(pipeline_svm, params_svm_poly)\n",
    "svm_result_poly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed: 49.2min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 581.1min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 1776.6min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 2192.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'grid_cv': GridSearchCV(cv=5, error_score=nan,\n",
       "              estimator=Pipeline(memory=None,\n",
       "                                 steps=[('vect',\n",
       "                                         TfidfVectorizer(analyzer='word',\n",
       "                                                         binary=False,\n",
       "                                                         decode_error='strict',\n",
       "                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                         encoding='utf-8',\n",
       "                                                         input='content',\n",
       "                                                         lowercase=True,\n",
       "                                                         max_df=1.0,\n",
       "                                                         max_features=None,\n",
       "                                                         min_df=1,\n",
       "                                                         ngram_range=(1, 1),\n",
       "                                                         norm='l2',\n",
       "                                                         preprocessor=None,\n",
       "                                                         smooth_idf=True,\n",
       "                                                         stop_words=None,\n",
       "                                                         strip_acce...\n",
       "                                             probability=False,\n",
       "                                             random_state=None, shrinking=True,\n",
       "                                             tol=0.001, verbose=False))],\n",
       "                                 verbose=False),\n",
       "              iid='deprecated', n_jobs=-1,\n",
       "              param_grid={'clf__C': [1, 10, 100, 1000],\n",
       "                          'clf__gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                         0.9],\n",
       "                          'clf__kernel': ['rbf'], 'clf__random_state': [11],\n",
       "                          'vect__ngram_range': [(1, 2)]},\n",
       "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "              scoring='f1', verbose=5),\n",
       " 'model': Pipeline(memory=None,\n",
       "          steps=[('vect',\n",
       "                  TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                  decode_error='strict',\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  encoding='utf-8', input='content',\n",
       "                                  lowercase=True, max_df=1.0, max_features=None,\n",
       "                                  min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                  preprocessor=None, smooth_idf=True,\n",
       "                                  stop_words=None, strip_accents=None,\n",
       "                                  sublinear_tf=False,\n",
       "                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                  tokenizer=None, use_idf=True,\n",
       "                                  vocabulary=None)),\n",
       "                 ('clf',\n",
       "                  SVC(C=10, break_ties=False, cache_size=200, class_weight=None,\n",
       "                      coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                      gamma=0.1, kernel='rbf', max_iter=-1, probability=False,\n",
       "                      random_state=11, shrinking=True, tol=0.001,\n",
       "                      verbose=False))],\n",
       "          verbose=False),\n",
       " 'f1_cv': 0.9162920983650459,\n",
       " 'f1_test': 0.913498035559699}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_svm = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', svm.SVC()),\n",
    "])\n",
    "\n",
    "\n",
    "params_svm_rbf ={\n",
    "    'vect__ngram_range': [(1,2)],  \n",
    "    'clf__kernel': ['rbf'], \n",
    "    'clf__C': [1, 10, 100, 1000],\n",
    "    'clf__gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'clf__random_state': [RANDOM_STATE],\n",
    "           }\n",
    "\n",
    "svm_result_rbf = model_fit_and_evaluate(pipeline_svm, params_svm_rbf)\n",
    "svm_result_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is \n",
    "SVM(C=10, break_ties=False, cache_size=200, class_weight=None,\n",
    "    coef0=0.0, decision_function_shape='ovr', degree=3,\n",
    "    gamma=0.1, kernel='rbf', max_iter=-1, probability=False,\n",
    "    random_state=11, shrinking=True, tol=0.001,\n",
    "    verbose=False)\n",
    "                      \n",
    "'f1_cv': 0.9162920983650459,\n",
    "'f1_test': 0.913498035559699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed: 90.6min remaining: 135.9min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 168.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'grid_cv': GridSearchCV(cv=5, error_score=nan,\n",
       "              estimator=Pipeline(memory=None,\n",
       "                                 steps=[('vect',\n",
       "                                         TfidfVectorizer(analyzer='word',\n",
       "                                                         binary=False,\n",
       "                                                         decode_error='strict',\n",
       "                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                         encoding='utf-8',\n",
       "                                                         input='content',\n",
       "                                                         lowercase=True,\n",
       "                                                         max_df=1.0,\n",
       "                                                         max_features=None,\n",
       "                                                         min_df=1,\n",
       "                                                         ngram_range=(1, 1),\n",
       "                                                         norm='l2',\n",
       "                                                         preprocessor=None,\n",
       "                                                         smooth_idf=True,\n",
       "                                                         stop_words=None,\n",
       "                                                         strip_acce...\n",
       "                                             degree=3, gamma='scale',\n",
       "                                             kernel='rbf', max_iter=-1,\n",
       "                                             probability=False,\n",
       "                                             random_state=None, shrinking=True,\n",
       "                                             tol=0.001, verbose=False))],\n",
       "                                 verbose=False),\n",
       "              iid='deprecated', n_jobs=4,\n",
       "              param_grid={'clf__C': [10], 'clf__gamma': [0.1],\n",
       "                          'clf__kernel': ['rbf'], 'clf__random_state': [11],\n",
       "                          'vect__ngram_range': [(1, 2)]},\n",
       "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "              scoring='f1', verbose=5),\n",
       " 'model': Pipeline(memory=None,\n",
       "          steps=[('vect',\n",
       "                  TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                  decode_error='strict',\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  encoding='utf-8', input='content',\n",
       "                                  lowercase=True, max_df=1.0, max_features=None,\n",
       "                                  min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                  preprocessor=None, smooth_idf=True,\n",
       "                                  stop_words=None, strip_accents=None,\n",
       "                                  sublinear_tf=False,\n",
       "                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                  tokenizer=None, use_idf=True,\n",
       "                                  vocabulary=None)),\n",
       "                 ('clf',\n",
       "                  SVC(C=10, break_ties=False, cache_size=200, class_weight=None,\n",
       "                      coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                      gamma=0.1, kernel='rbf', max_iter=-1, probability=False,\n",
       "                      random_state=11, shrinking=True, tol=0.001,\n",
       "                      verbose=False))],\n",
       "          verbose=False),\n",
       " 'f1_cv': 0.9162920983650459,\n",
       " 'f1_test': 0.913498035559699}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_best = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', svm.SVC()),\n",
    "])\n",
    "\n",
    "\n",
    "params_best ={\n",
    "    'vect__ngram_range': [(1,2)],  \n",
    "    'clf__kernel': ['rbf'], \n",
    "    'clf__C': [10],\n",
    "    'clf__gamma': [0.1],\n",
    "    'clf__random_state': [RANDOM_STATE],\n",
    "           }\n",
    "\n",
    "result_best = model_fit_and_evaluate(pipeline_best, params_best)\n",
    "result_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grid_cv': GridSearchCV(cv=5, error_score=nan,\n",
       "              estimator=Pipeline(memory=None,\n",
       "                                 steps=[('vect',\n",
       "                                         TfidfVectorizer(analyzer='word',\n",
       "                                                         binary=False,\n",
       "                                                         decode_error='strict',\n",
       "                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                         encoding='utf-8',\n",
       "                                                         input='content',\n",
       "                                                         lowercase=True,\n",
       "                                                         max_df=1.0,\n",
       "                                                         max_features=None,\n",
       "                                                         min_df=1,\n",
       "                                                         ngram_range=(1, 1),\n",
       "                                                         norm='l2',\n",
       "                                                         preprocessor=None,\n",
       "                                                         smooth_idf=True,\n",
       "                                                         stop_words=None,\n",
       "                                                         strip_acce...\n",
       "                                             degree=3, gamma='scale',\n",
       "                                             kernel='rbf', max_iter=-1,\n",
       "                                             probability=False,\n",
       "                                             random_state=None, shrinking=True,\n",
       "                                             tol=0.001, verbose=False))],\n",
       "                                 verbose=False),\n",
       "              iid='deprecated', n_jobs=4,\n",
       "              param_grid={'clf__C': [10], 'clf__gamma': [0.1],\n",
       "                          'clf__kernel': ['rbf'], 'clf__random_state': [11],\n",
       "                          'vect__ngram_range': [(1, 2)]},\n",
       "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "              scoring='f1', verbose=5),\n",
       " 'model': Pipeline(memory=None,\n",
       "          steps=[('vect',\n",
       "                  TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                  decode_error='strict',\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  encoding='utf-8', input='content',\n",
       "                                  lowercase=True, max_df=1.0, max_features=None,\n",
       "                                  min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                  preprocessor=None, smooth_idf=True,\n",
       "                                  stop_words=None, strip_accents=None,\n",
       "                                  sublinear_tf=False,\n",
       "                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                  tokenizer=None, use_idf=True,\n",
       "                                  vocabulary=None)),\n",
       "                 ('clf',\n",
       "                  SVC(C=10, break_ties=False, cache_size=200, class_weight=None,\n",
       "                      coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                      gamma=0.1, kernel='rbf', max_iter=-1, probability=False,\n",
       "                      random_state=11, shrinking=True, tol=0.001,\n",
       "                      verbose=False))],\n",
       "          verbose=False),\n",
       " 'f1_cv': 0.9162920983650459,\n",
       " 'f1_test': 0.913498035559699}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
