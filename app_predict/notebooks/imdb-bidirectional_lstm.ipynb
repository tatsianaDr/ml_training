{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This notebook will build a Bidirectional LSTM network using keras to solve classification sentiment problem for movie reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import **libraries**, import **custom scripts** and define **constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Dropout, Input, GlobalMaxPool1D \n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# import all our functions\n",
    "import os,sys,inspect\n",
    "currentdir=os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir=os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "from usr.lib.preprocessing import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition constants\n",
    "RANDOM_STATE = 11\n",
    "TEST_SIZE = 0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data and applying the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production.   the filming t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one of the other reviewers has mentioned that ...          1\n",
       "1  a wonderful little production.   the filming t...          1\n",
       "2  i thought this was a wonderful way to spend ti...          1\n",
       "3  basically there's a family where a little boy ...          0\n",
       "4  petter mattei's \"love in the time of money\" is...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import & display data\n",
    "data = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n",
    "data['sentiment'] = data['sentiment'].replace({'positive' : 1, 'negative' : 0})\n",
    "data = data.drop_duplicates()\n",
    "data['review'] = data['review'].apply(lambda x: preprocessing.preprocessing_text(x))\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data for the training, the testing and the validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.review\n",
    "y = data.sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=TEST_SIZE, \n",
    "                                                    random_state=RANDOM_STATE, \n",
    "                                                    stratify = y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, \n",
    "                                                    y_train,\n",
    "                                                    test_size=TEST_SIZE, \n",
    "                                                    random_state=RANDOM_STATE, \n",
    "                                                    stratify = y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "max_len = 500\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features, oov_token='unk')\n",
    "\n",
    "# only fit on train\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_val_pad = pad_sequences(X_val_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "### Let's define the function for building and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for f1 metric\n",
    "def get_f1(y_true, y_pred): \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "\n",
    "def build_model(embed_dim=128, lstm_out=64, dropout=0.5, optimizer='adam', activation='relu', units=32 ):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embed_dim, input_length=max_len))\n",
    "    model.add(Bidirectional(LSTM(lstm_out)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units, activation=activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer, 'binary_crossentropy', metrics=[get_f1])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(embed_dim=128, \n",
    "                lstm_out=64, \n",
    "                dropout=0.5, \n",
    "                optimizer='adam',\n",
    "                batch_size=32,\n",
    "                epochs=20,\n",
    "                activation='relu', \n",
    "                units=32, \n",
    "                log_dir='logs/bilstm',\n",
    "                filepath='model.hdf5'):\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', \n",
    "                               patience=3)\n",
    "    cp_callback = ModelCheckpoint(filepath=filepath,\n",
    "                                  save_best_only=True,\n",
    "                                  verbose=1)\n",
    "    \n",
    "    model = build_model(embed_dim, lstm_out, dropout, optimizer)\n",
    "    model.summary()\n",
    "    history = model.fit(X_train_pad, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=2, \n",
    "                        callbacks=[tensorboard_callback, early_stop, cp_callback],                    \n",
    "                        validation_data=(X_val_pad, y_val))\n",
    "    return history\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of exploring let's save to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_research_df = pd.DataFrame(columns=['Model',\n",
    "                                           'loss',\n",
    "                                           'f1_score',\n",
    "                                           'val_loss',\n",
    "                                           'val_f1'], )\n",
    "results = {}\n",
    "# add data to result research dataframe\n",
    "def add_data_df(table_df_for_add, model_name, history_research):\n",
    "    index = history_research['val_loss'].index(min(history_research['val_loss']))\n",
    "    model_research = (model_name, history_research['loss'][index], history_research['get_f1'][index], history_research['val_loss'][index], history_research['val_get_f1'][index])\n",
    "    if any([list(row.values ) == list(model_research) for _, row in table_df_for_add.iterrows()]):\n",
    "        return\n",
    "    table_df_for_add.loc[len(table_df_for_add)] = model_research\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_1\n",
    "The model with default params for this model with `dropout=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,662,977\n",
      "Trainable params: 2,662,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 35822 samples, validate on 6322 samples\n",
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.30514, saving model to Model_1_01-0.86.hdf5\n",
      "35822/35822 - 460s - loss: 0.3657 - get_f1: 0.8196 - val_loss: 0.3051 - val_get_f1: 0.8625\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.30514\n",
      "35822/35822 - 456s - loss: 0.3004 - get_f1: 0.8770 - val_loss: 0.3453 - val_get_f1: 0.8647\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.30514 to 0.30006, saving model to Model_1_03-0.89.hdf5\n",
      "35822/35822 - 449s - loss: 0.1812 - get_f1: 0.9307 - val_loss: 0.3001 - val_get_f1: 0.8932\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30006\n",
      "35822/35822 - 452s - loss: 0.1187 - get_f1: 0.9572 - val_loss: 0.3823 - val_get_f1: 0.8850\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30006\n",
      "35822/35822 - 447s - loss: 0.0839 - get_f1: 0.9712 - val_loss: 0.3544 - val_get_f1: 0.8768\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.30006\n",
      "35822/35822 - 444s - loss: 0.0659 - get_f1: 0.9771 - val_loss: 0.4597 - val_get_f1: 0.8855\n"
     ]
    }
   ],
   "source": [
    "history_1 = train_model(filepath='Model_1_{epoch:02d}-{val_get_f1:.2f}.hdf5',\n",
    "           log_dir='logs/bilstm/model_1',\n",
    "           dropout=0)\n",
    "results['model_1'] = history_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_2\n",
    "The model with `dropout=0.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,662,977\n",
      "Trainable params: 2,662,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 35822 samples, validate on 6322 samples\n",
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.38918, saving model to Model_2_01-0.85.hdf5\n",
      "35822/35822 - 465s - loss: 0.4299 - get_f1: 0.7973 - val_loss: 0.3892 - val_get_f1: 0.8479\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.38918\n",
      "35822/35822 - 454s - loss: 0.2717 - get_f1: 0.8911 - val_loss: 0.4022 - val_get_f1: 0.8279\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38918 to 0.32866, saving model to Model_2_03-0.87.hdf5\n",
      "35822/35822 - 451s - loss: 0.2406 - get_f1: 0.8973 - val_loss: 0.3287 - val_get_f1: 0.8739\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32866\n",
      "35822/35822 - 457s - loss: 0.1286 - get_f1: 0.9534 - val_loss: 0.3471 - val_get_f1: 0.8744\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32866\n",
      "35822/35822 - 467s - loss: 0.0847 - get_f1: 0.9709 - val_loss: 0.4089 - val_get_f1: 0.8699\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32866\n",
      "35822/35822 - 446s - loss: 0.0792 - get_f1: 0.9716 - val_loss: 0.4648 - val_get_f1: 0.8769\n"
     ]
    }
   ],
   "source": [
    "history_2 = train_model(filepath='Model_2_{epoch:02d}-{val_get_f1:.2f}.hdf5',\n",
    "           log_dir='logs/bilstm/model_2',\n",
    "           dropout=0.2)\n",
    "results['model_2'] = history_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_3\n",
    "The model with `dropout=0.2` and `activation=tanh` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,662,977\n",
      "Trainable params: 2,662,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 35822 samples, validate on 6322 samples\n",
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.48447, saving model to Model_3_01-0.70.hdf5\n",
      "35822/35822 - 472s - loss: 0.4466 - get_f1: 0.7796 - val_loss: 0.4845 - val_get_f1: 0.6967\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.48447 to 0.30540, saving model to Model_3_02-0.87.hdf5\n",
      "35822/35822 - 451s - loss: 0.3280 - get_f1: 0.8607 - val_loss: 0.3054 - val_get_f1: 0.8725\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30540\n",
      "35822/35822 - 454s - loss: 0.2053 - get_f1: 0.9226 - val_loss: 0.3079 - val_get_f1: 0.8762\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30540\n",
      "35822/35822 - 453s - loss: 0.1403 - get_f1: 0.9490 - val_loss: 0.3184 - val_get_f1: 0.8863\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.30540\n",
      "35822/35822 - 460s - loss: 0.0985 - get_f1: 0.9648 - val_loss: 0.3487 - val_get_f1: 0.8821\n"
     ]
    }
   ],
   "source": [
    "history_3 = train_model(filepath='Model_3_{epoch:02d}-{val_get_f1:.2f}.hdf5',\n",
    "           log_dir='logs/bilstm/model_3', \n",
    "           dropout=0.2,\n",
    "           activation='tanh')\n",
    "results['model_3'] = history_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_4\n",
    "The model with `dropout=0.2` and `activation=tanh` and `units=64`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,662,977\n",
      "Trainable params: 2,662,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 35822 samples, validate on 6322 samples\n",
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33473, saving model to Model_4_01-0.85.hdf5\n",
      "35822/35822 - 471s - loss: 0.4060 - get_f1: 0.8222 - val_loss: 0.3347 - val_get_f1: 0.8460\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.33473\n",
      "35822/35822 - 466s - loss: 0.2260 - get_f1: 0.9120 - val_loss: 0.3830 - val_get_f1: 0.8172\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33473 to 0.29405, saving model to Model_4_03-0.88.hdf5\n",
      "35822/35822 - 456s - loss: 0.1654 - get_f1: 0.9394 - val_loss: 0.2941 - val_get_f1: 0.8773\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.29405\n",
      "35822/35822 - 449s - loss: 0.1067 - get_f1: 0.9606 - val_loss: 0.3182 - val_get_f1: 0.8834\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.29405\n",
      "35822/35822 - 454s - loss: 0.1101 - get_f1: 0.9601 - val_loss: 0.3825 - val_get_f1: 0.8806\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.29405\n",
      "35822/35822 - 447s - loss: 0.0596 - get_f1: 0.9798 - val_loss: 0.4826 - val_get_f1: 0.8772\n"
     ]
    }
   ],
   "source": [
    "history_4 = train_model(filepath='Model_4_{epoch:02d}-{val_get_f1:.2f}.hdf5',\n",
    "                        log_dir='logs/bilstm/model_4',\n",
    "                        dropout=0.2,\n",
    "                        units=64,\n",
    "                       activation='tanh')\n",
    "results['model_4'] = history_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_5\n",
    "The model with \n",
    "* `dropout=0.2` \n",
    "* `activation=relu`\n",
    "* `units=64`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,662,977\n",
      "Trainable params: 2,662,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 35822 samples, validate on 6322 samples\n",
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28441, saving model to Model_5_01-0.88.hdf5\n",
      "35822/35822 - 459s - loss: 0.4306 - get_f1: 0.7906 - val_loss: 0.2844 - val_get_f1: 0.8837\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.28441\n",
      "35822/35822 - 464s - loss: 0.2323 - get_f1: 0.9105 - val_loss: 0.2917 - val_get_f1: 0.8804\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28441\n",
      "35822/35822 - 468s - loss: 0.1690 - get_f1: 0.9385 - val_loss: 0.3075 - val_get_f1: 0.8871\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28441\n",
      "35822/35822 - 475s - loss: 0.1137 - get_f1: 0.9596 - val_loss: 0.3478 - val_get_f1: 0.8945\n"
     ]
    }
   ],
   "source": [
    "history_5 = train_model(filepath='Model_5_{epoch:02d}-{val_get_f1:.2f}.hdf5',\n",
    "                        log_dir='logs/bilstm/model_5',\n",
    "                        dropout=0.2,\n",
    "                        units=64)\n",
    "results['model_5'] = history_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_6\n",
    "The model with \n",
    "* `dropout=0.2` \n",
    "* `activation=relu`\n",
    "* `units=64`\n",
    "* `lstm_out=128`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,831,425\n",
      "Trainable params: 2,831,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 35822 samples, validate on 6322 samples\n",
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28337, saving model to Model_6_01-0.88.hdf5\n",
      "35822/35822 - 753s - loss: 0.4512 - get_f1: 0.7769 - val_loss: 0.2834 - val_get_f1: 0.8794\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.28337 to 0.27470, saving model to Model_6_02-0.89.hdf5\n",
      "35822/35822 - 756s - loss: 0.2661 - get_f1: 0.8961 - val_loss: 0.2747 - val_get_f1: 0.8950\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27470\n",
      "35822/35822 - 765s - loss: 0.1876 - get_f1: 0.9300 - val_loss: 0.2900 - val_get_f1: 0.8806\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27470\n",
      "35822/35822 - 747s - loss: 0.1278 - get_f1: 0.9545 - val_loss: 0.3074 - val_get_f1: 0.8893\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27470\n",
      "35822/35822 - 756s - loss: 0.0929 - get_f1: 0.9683 - val_loss: 0.3901 - val_get_f1: 0.8723\n"
     ]
    }
   ],
   "source": [
    "history_6 = train_model(filepath='Model_6_{epoch:02d}-{val_get_f1:.2f}.hdf5',\n",
    "                        log_dir='logs/bilstm/model_6',\n",
    "                        dropout=0.2,\n",
    "                       units=64,\n",
    "                       lstm_out=128)\n",
    "results['model_6'] = history_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model_7\n",
    "The model with \n",
    "* `dropout=0.2` \n",
    "* `activation=tanh`\n",
    "* `units=64`\n",
    "* `lstm_out=128`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 500, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,831,425\n",
      "Trainable params: 2,831,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 35822 samples, validate on 6322 samples\n",
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39577, saving model to Model_7_01-0.84.hdf5\n",
      "35822/35822 - 758s - loss: 0.4630 - get_f1: 0.7781 - val_loss: 0.3958 - val_get_f1: 0.8406\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39577 to 0.28161, saving model to Model_7_02-0.88.hdf5\n",
      "35822/35822 - 736s - loss: 0.3968 - get_f1: 0.8072 - val_loss: 0.2816 - val_get_f1: 0.8812\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.28161 to 0.24781, saving model to Model_7_03-0.90.hdf5\n",
      "35822/35822 - 744s - loss: 0.2006 - get_f1: 0.9223 - val_loss: 0.2478 - val_get_f1: 0.9000\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24781\n",
      "35822/35822 - 754s - loss: 0.1240 - get_f1: 0.9561 - val_loss: 0.2943 - val_get_f1: 0.8949\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24781\n",
      "35822/35822 - 756s - loss: 0.0767 - get_f1: 0.9744 - val_loss: 0.3416 - val_get_f1: 0.8911\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.24781\n",
      "35822/35822 - 744s - loss: 0.0462 - get_f1: 0.9853 - val_loss: 0.4407 - val_get_f1: 0.8968\n"
     ]
    }
   ],
   "source": [
    "history_7 = train_model(filepath='Model_7_{epoch:02d}-{val_get_f1:.2f}.hdf5',\n",
    "           log_dir='logs/bilstm/model_7',\n",
    "           dropout=0.2,\n",
    "                       units=64,\n",
    "                       lstm_out=128,\n",
    "                       activation='tanh')\n",
    "results['model_7'] = history_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of exploring models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    add_data_df(models_research_df, result, results.get(result).history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>0.181231</td>\n",
       "      <td>0.930693</td>\n",
       "      <td>0.300055</td>\n",
       "      <td>0.893155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>0.240558</td>\n",
       "      <td>0.897326</td>\n",
       "      <td>0.328663</td>\n",
       "      <td>0.873913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>0.327967</td>\n",
       "      <td>0.860688</td>\n",
       "      <td>0.305403</td>\n",
       "      <td>0.872537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model_4</td>\n",
       "      <td>0.165357</td>\n",
       "      <td>0.939424</td>\n",
       "      <td>0.294052</td>\n",
       "      <td>0.877311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model_5</td>\n",
       "      <td>0.430557</td>\n",
       "      <td>0.790560</td>\n",
       "      <td>0.284407</td>\n",
       "      <td>0.883737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model_6</td>\n",
       "      <td>0.266093</td>\n",
       "      <td>0.896062</td>\n",
       "      <td>0.274701</td>\n",
       "      <td>0.894998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model_7</td>\n",
       "      <td>0.200573</td>\n",
       "      <td>0.922255</td>\n",
       "      <td>0.247807</td>\n",
       "      <td>0.899970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model      loss  f1_score  val_loss    val_f1\n",
       "0  model_1  0.181231  0.930693  0.300055  0.893155\n",
       "1  model_2  0.240558  0.897326  0.328663  0.873913\n",
       "2  model_3  0.327967  0.860688  0.305403  0.872537\n",
       "3  model_4  0.165357  0.939424  0.294052  0.877311\n",
       "4  model_5  0.430557  0.790560  0.284407  0.883737\n",
       "5  model_6  0.266093  0.896062  0.274701  0.894998\n",
       "6  model_7  0.200573  0.922255  0.247807  0.899970"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_research_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
