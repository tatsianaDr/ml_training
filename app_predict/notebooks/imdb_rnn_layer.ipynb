{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uqF0hn9KqDlT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab_type": "text",
    "id": "XDtgM15IqDlX"
   },
   "source": [
    "## Introduction\n",
    "This notebook will build a simple RNN model using keras to solve classification sentiment problem for movie reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WT1TVoawqDld"
   },
   "source": [
    "### Import libraries,  import custom scripts and define constants  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVpehAQgqDle"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, SimpleRNN, SpatialDropout1D, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X6F0ZZ2MqDln"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eh-4tF9-qT7w"
   },
   "source": [
    "\n",
    "##### **Mount** the google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5fMiN6T_qTSz",
    "outputId": "89825379-a753-4ab8-8722-c587577fe83b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fDMxmJ6_qezJ"
   },
   "outputs": [],
   "source": [
    "# import all our functions\n",
    "import os,sys\n",
    "sys.path.insert(0,'/content/drive/My Drive/Colab Notebooks/ml_training/app_predict/')\n",
    "from src import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39_2ChzUqDlk"
   },
   "outputs": [],
   "source": [
    "#definition constants\n",
    "RANDOM_STATE = 11\n",
    "TEST_SIZE = 0.15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ajnQM4yqDlr"
   },
   "source": [
    "###  Loading the data and applying the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyQQSJMcqeLo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "V20wSwSVqDls",
    "outputId": "5ea6abaa-78cf-41fb-eab7-f8834b879cfa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production.   the filming t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one of the other reviewers has mentioned that ...          1\n",
       "1  a wonderful little production.   the filming t...          1\n",
       "2  i thought this was a wonderful way to spend ti...          1\n",
       "3  basically there's a family where a little boy ...          0\n",
       "4  petter mattei's \"love in the time of money\" is...          1"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import & display data\n",
    "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ml_training/data/IMDB_Dataset.csv')\n",
    "data['sentiment'] = data['sentiment'].replace({'positive' : 1, 'negative' : 0})\n",
    "data = data.drop_duplicates()\n",
    "data['review'] = data['review'].apply(lambda x: preprocessing.preprocessing_text(x))\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fS8HMj2qDlv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SmR4IkdqDlx"
   },
   "source": [
    "Split the data for the training, the testing and the validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0NUhyrqtqDlx"
   },
   "outputs": [],
   "source": [
    "X = data.review\n",
    "y = data.sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=TEST_SIZE, \n",
    "                                                    random_state=RANDOM_STATE, \n",
    "                                                    stratify = y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, \n",
    "                                                    y_train,\n",
    "                                                    test_size=TEST_SIZE, \n",
    "                                                    random_state=RANDOM_STATE, \n",
    "                                                    stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thNtq8FAqDl0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hFuQ9WwHqDl7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_qJ-9kcxqDmA"
   },
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjRWQkHUqDmA"
   },
   "outputs": [],
   "source": [
    "MAX_FEATURES = 50000\n",
    "MAX_LEN = 500\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_FEATURES, oov_token='unk')\n",
    "\n",
    "# only fit on train\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN)\n",
    "X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_LEN)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6c4xX-vzqDmD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwRipkDYqDmF"
   },
   "source": [
    "### Create model\n",
    "For this step let's try to use the keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LcdbJXlNqDmG"
   },
   "outputs": [],
   "source": [
    "#function for f1 metric\n",
    "def get_f1(y_true, y_pred): \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "c3OD41NSqDmI",
    "outputId": "85994e45-5149-433d-fac0-87343c45edbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.49410, saving model to model_rnn.hdf5\n",
      "1120/1120 - 921s - loss: 0.5268 - get_f1: 0.7248 - val_loss: 0.4941 - val_get_f1: 0.7611\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.49410 to 0.43275, saving model to model_rnn.hdf5\n",
      "1120/1120 - 978s - loss: 0.4024 - get_f1: 0.8197 - val_loss: 0.4328 - val_get_f1: 0.7821\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.43275\n",
      "1120/1120 - 891s - loss: 0.3975 - get_f1: 0.8204 - val_loss: 0.5430 - val_get_f1: 0.7318\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.43275\n",
      "1120/1120 - 858s - loss: 0.2412 - get_f1: 0.9012 - val_loss: 0.5568 - val_get_f1: 0.7634\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.43275\n",
      "1120/1120 - 831s - loss: 0.1502 - get_f1: 0.9418 - val_loss: 0.5923 - val_get_f1: 0.7838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff1547d8710>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBED_DIM = 512\n",
    "RNN_OUT = 32\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "main_input = Input(shape=(MAX_LEN,), dtype='int32', name='main_input')\n",
    "\n",
    "x = Embedding(output_dim=EMBED_DIM, input_dim=MAX_FEATURES, input_length=MAX_LEN)(main_input)\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "x = SimpleRNN(RNN_OUT)(x)\n",
    "\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[main_input], outputs=[main_output])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[get_f1])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           patience=3)\n",
    "cp_callback = ModelCheckpoint(filepath='model_rnn.hdf5',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "callbacks = [cp_callback, early_stop]\n",
    "\n",
    "model.fit(X_train_pad, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,  \n",
    "          verbose=2,                   \n",
    "          callbacks=callbacks,                    \n",
    "          validation_data=(X_val_pad, y_val),                     \n",
    "          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xjV9KYYgqDmN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "XGBKth0d-pFe",
    "outputId": "38d9e8c8-e05e-4ea0-db9c-90d3e718fad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51726, saving model to model_rnn.hdf5\n",
      "1120/1120 - 854s - loss: 0.6190 - get_f1: 0.6282 - val_loss: 0.5173 - val_get_f1: 0.7284\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.51726 to 0.41309, saving model to model_rnn.hdf5\n",
      "1120/1120 - 866s - loss: 0.3944 - get_f1: 0.8267 - val_loss: 0.4131 - val_get_f1: 0.8209\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.41309\n",
      "1120/1120 - 860s - loss: 0.2170 - get_f1: 0.9126 - val_loss: 0.5261 - val_get_f1: 0.8155\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.41309\n",
      "1120/1120 - 867s - loss: 0.1126 - get_f1: 0.9582 - val_loss: 0.6042 - val_get_f1: 0.8079\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.41309\n",
      "1120/1120 - 858s - loss: 0.0798 - get_f1: 0.9719 - val_loss: 0.6682 - val_get_f1: 0.7933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff152da0278>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "main_input = Input(shape=(MAX_LEN,), dtype='int32', name='main_input')\n",
    "\n",
    "x = Embedding(output_dim=EMBED_DIM, input_dim=MAX_FEATURES, input_length=MAX_LEN)(main_input)\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "x = SimpleRNN(RNN_OUT)(x)\n",
    "\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[main_input], outputs=[main_output])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[get_f1])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           patience=3)\n",
    "cp_callback = ModelCheckpoint(filepath='model_rnn.hdf5',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "callbacks = [cp_callback, early_stop]\n",
    "\n",
    "model.fit(X_train_pad, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,  \n",
    "          verbose=2,                   \n",
    "          callbacks=callbacks,                    \n",
    "          validation_data=(X_val_pad, y_val),                     \n",
    "          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lAYLUyFo-pIY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rnn-network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
